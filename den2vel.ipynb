{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "2af0e65b",
   "metadata": {
    "cellId": "jftzi84moejotkzs217x0b"
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Failed to run cell: internal error. Please try again",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#!g1.1\n",
    "from pathlib import Path\n",
    "no_obs_path = Path('/home/jupyter/mnt/datasets/den2vel/datasets/2D_no_obs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "e0e74033",
   "metadata": {
    "cellId": "f3kajhkxwn9s9s409e17fh"
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Failed to run cell: internal error. Please try again",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#!g1.1\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "9c6d6c32",
   "metadata": {
    "cellId": "jolsyg0d1vqo3flh3zt26g"
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Failed to run cell: internal error. Please try again",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from typing import Union, Callable, Optional, List\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "04fbce2c",
   "metadata": {
    "cellId": "pv4ww5g24mte6tsi07969"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "245it [00:00, 404.38it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "val_sims = ['/home/jupyter/mnt/datasets/den2vel/datasets/2D_no_obs/v01/sim_1001',\n",
    "            '/home/jupyter/mnt/datasets/den2vel/datasets/2D_no_obs/v01/sim_1030',\n",
    "            '/home/jupyter/mnt/datasets/den2vel/datasets/2D_no_obs/v01/sim_1058',\n",
    "            '/home/jupyter/mnt/datasets/den2vel/datasets/2D_no_obs/v02/sim_1001',\n",
    "            '/home/jupyter/mnt/datasets/den2vel/datasets/2D_no_obs/v02/sim_1030',\n",
    "            '/home/jupyter/mnt/datasets/den2vel/datasets/2D_no_obs/v02/sim_1058',\n",
    "            '/home/jupyter/mnt/datasets/den2vel/datasets/2D_no_obs/v03/sim_1001',\n",
    "            '/home/jupyter/mnt/datasets/den2vel/datasets/2D_no_obs/v03/sim_1030',\n",
    "            '/home/jupyter/mnt/datasets/den2vel/datasets/2D_no_obs/v03/sim_1058',\n",
    "            '/home/jupyter/mnt/datasets/den2vel/datasets/2D_no_obs/v04/sim_1001',\n",
    "            '/home/jupyter/mnt/datasets/den2vel/datasets/2D_no_obs/v04/sim_1030',\n",
    "            '/home/jupyter/mnt/datasets/den2vel/datasets/2D_no_obs/v04/sim_1058']\n",
    "\n",
    "train_sims = []\n",
    "\n",
    "for p in tqdm(os.walk(no_obs_path)):\n",
    "    if 'sim' in p[0]:\n",
    "        if p[0] not in val_sims:\n",
    "            train_sims.append(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "id": "b592676b",
   "metadata": {
    "cellId": "fvovf9yvlpmdmi584f4frn"
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Failed to run cell: internal error. Please try again",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#!g1.1\n",
    "class NoObsDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, sims_pth: List[Union[str, Path]],transforms: Optional[Callable] = None):\n",
    "        super().__init__()\n",
    "        self._transforms = transforms \n",
    "        self.sims_pth = sims_pth\n",
    "        self.density = []\n",
    "        self.velocity = []\n",
    "        self.s_dict = {}\n",
    "        \n",
    "        for s in tqdm(sims_pth):\n",
    "            p = next(os.walk(s))\n",
    "            for f in p[-1]:\n",
    "                if 'npz' == f[-3:]:\n",
    "                    if 'density' in f:\n",
    "                        self.density.append(f'{p[0]}/{f}')\n",
    "                    else:\n",
    "                        self.velocity.append(f'{p[0]}/{f}')\n",
    "                elif 'json' in f:\n",
    "                    with open(f'{p[0]}/{f}', 'r') as f:\n",
    "                        loaded = json.load(f)\n",
    "                        self.s_dict[p[0]] = np.array([float(loaded['bnds']), \n",
    "                                                      float(loaded['buoyFac'])], dtype=np.float32)\n",
    "                            \n",
    "                            \n",
    "        assert len(self.density) == len(self.velocity)\n",
    "        \n",
    "        self.density.sort()\n",
    "        self.velocity.sort()\n",
    "                        \n",
    "    @property\n",
    "    def transforms(self):\n",
    "        return self._transforms\n",
    "    \n",
    "    @transforms.setter\n",
    "    def transforms(self, transforms: Callable):\n",
    "        self._transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.density)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        den_pth = self.density[index]\n",
    "        den = np.ascontiguousarray(np.load(den_pth)['arr_0'][0, ::-1])\n",
    "        vel = np.ascontiguousarray(np.load(self.velocity[index])['arr_0'][0, ::-1, :, :-1])\n",
    "        i = den_pth.find('v0')\n",
    "        s_pth = den_pth[:i + 12]\n",
    "        s = self.s_dict[s_pth]\n",
    "        \n",
    "        if self._transforms is not None:\n",
    "            den = self._transforms(den)\n",
    "            vel = self._transforms(vel)\n",
    "        return den, vel, torch.from_numpy(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "id": "8f625cc6",
   "metadata": {
    "cellId": "u4a24fsu493fsw6fcoff7"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import torchvision\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "id": "de307b30",
   "metadata": {
    "cellId": "himv0rpz186ab8mfcx8o5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44e638296344748a59510d42e3805c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=228.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9e9f04d7eb45c380f03d94c3d8b449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "no_obs_train_dataset = NoObsDataset(train_sims, transforms=transform)\n",
    "no_obs_val_dataset = NoObsDataset(val_sims, transforms=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "id": "806e35da",
   "metadata": {
    "cellId": "igdapsdpqnea74g28h9g"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "BATCH_SIZE = 2\n",
    "train_loader = torch.utils.data.DataLoader(no_obs_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "val_loader = torch.utils.data.DataLoader(no_obs_val_dataset, batch_size=1, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "c631e505",
   "metadata": {
    "cellId": "qfompltsllcgconntu32h"
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Failed to run cell: internal error. Please try again",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#!g1.1\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_c: int, out_c: int):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Sequential(nn.Conv2d(in_c, out_c, 3, padding=1, padding_mode='replicate'),\n",
    "                                    nn.InstanceNorm2d(out_c),\n",
    "                                    nn.LeakyReLU())\n",
    "        self.conv_2 = nn.Sequential(nn.Conv2d(out_c, out_c, 3, padding=1, padding_mode='replicate'),\n",
    "                                    nn.InstanceNorm2d(out_c))\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        y = self.conv_1(x)\n",
    "        y = self.conv_2(y)\n",
    "        return (x + y) / 1.41\n",
    "    \n",
    "    \n",
    "class SubNetS(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_c: int):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AvgPool2d(8, 8)\n",
    "        self.flatten_conv = nn.Sequential(nn.Conv2d(16, 16, 3, padding=1, padding_mode='replicate'), \n",
    "                                          nn.AvgPool2d(2, 2), nn.LeakyReLU())\n",
    "        self.s_out = nn.Sequential(nn.Flatten(), nn.Linear(16 * 4 * 4, 2))\n",
    "        self.s_in = nn.Linear(4, 4 * 8 * 8)\n",
    "        self.conv_out = nn.Sequential(nn.Conv2d(4, 8, 3, padding=1, padding_mode='replicate'),\n",
    "                                      nn.LeakyReLU(),\n",
    "                                      nn.Conv2d(8, 16, 3, padding=1, padding_mode='replicate'),\n",
    "                                      nn.LeakyReLU())\n",
    "        self.unpool = nn.Sequential(nn.Upsample((64, 64), mode='bilinear', align_corners=False), \n",
    "                                    nn.Conv2d(16, 16, 1), nn.ReLU())\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, s: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten_conv(x)\n",
    "        s_out = self.s_out(x)\n",
    "        if s is None:\n",
    "            s = -torch.ones_like(s_out)\n",
    "            s.requires_grad = False\n",
    "        x = torch.cat([s_out, s], dim=1)\n",
    "        x = self.s_in(x)\n",
    "        x = x.reshape(-1, 4, 8, 8)\n",
    "        x = self.conv_out(x)\n",
    "        x = self.unpool(x)\n",
    "        return x, s_out\n",
    "            \n",
    "        \n",
    "class SubNetKE(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_c: int):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Sequential(nn.Conv2d(in_c, 8, 3, padding=1, padding_mode='replicate'),\n",
    "                                    nn.AvgPool2d(2, 2), \n",
    "                                    nn.InstanceNorm2d(8),\n",
    "                                    nn.LeakyReLU())\n",
    "        self.conv_2 = nn.Sequential(nn.Conv2d(8, 4, 3, padding=1, padding_mode='replicate'),\n",
    "                                    nn.AvgPool2d(2, 2),\n",
    "                                    nn.InstanceNorm2d(4),\n",
    "                                    nn.LeakyReLU())\n",
    "        self.ke_out_conv = nn.Conv2d(4, 1, 1)\n",
    "        self.ke_in_conv = nn.Sequential(nn.Conv2d(2, 2, 3, padding=1, padding_mode='replicate'), nn.LeakyReLU())\n",
    "        self.conv_5 = nn.Sequential(nn.Conv2d(2, 2, 3, padding=1, padding_mode='replicate'), nn.LeakyReLU(0.2))\n",
    "        self.unpool = nn.Sequential(nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True), nn.Conv2d(2, 1, 1))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, ke: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        ke_out = self.ke_out_conv(x)\n",
    "        if ke is None:\n",
    "            ke = -torch.ones_like(ke_out)\n",
    "            ke.requires_grad = False\n",
    "        x = torch.cat([ke_out, ke], dim=1) if x.ndim == 4 else torch.cat([ke_out, ke], dim=0)\n",
    "        x = self.ke_in_conv(x)\n",
    "        x = self.conv_5(x)\n",
    "        return self.unpool(x), ke_out\n",
    "        \n",
    "        \n",
    "class SubNetW(nn.Module):\n",
    "    def __init__(self, in_c: int):\n",
    "        super().__init__()\n",
    "        self.up1 = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True), \n",
    "                                 nn.Conv2d(in_c, 32, 3, padding=1, padding_mode='replicate'),\n",
    "                                 nn.InstanceNorm2d(32),\n",
    "                                 nn.LeakyReLU())\n",
    "        self.up2 = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True), \n",
    "                                 nn.Conv2d(32, 16, 3, padding=1),\n",
    "                                 nn.InstanceNorm2d(16),\n",
    "                                 nn.LeakyReLU())\n",
    "        self.w_out = nn.Conv2d(16, 1, 7, padding='same', padding_mode='replicate')\n",
    "        self.w_in = nn.Sequential(nn.Conv2d(2, 16, 5, padding='same', padding_mode='replicate'),\n",
    "                                  nn.AvgPool2d(2, 2),\n",
    "                                  nn.InstanceNorm2d(16),\n",
    "                                  nn.LeakyReLU())\n",
    "        \n",
    "        self.down = nn.Sequential(nn.Conv2d(16, 24, 5, padding='same', padding_mode='replicate'),\n",
    "                                  nn.AvgPool2d(2, 2),\n",
    "                                  nn.InstanceNorm2d(24),\n",
    "                                  nn.LeakyReLU())\n",
    "        \n",
    "        self.conv_out = nn.Conv2d(24, 32, 3, padding=1)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, w: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        x = self.up1(x)\n",
    "        x = self.up2(x)\n",
    "        w_out = self.w_out(x)\n",
    "        if w is None:\n",
    "            w = -torch.ones_like(w_out)\n",
    "            w.requires_grad = False\n",
    "        x = torch.cat([w_out, w], dim=1) if x.ndim == 4 else torch.cat([w_out, w], dim=0)\n",
    "        x = self.w_in(x)\n",
    "        x = self.down(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x, w_out\n",
    "    \n",
    "    \n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_c: int, out_c: int, s_subnet: nn.Module, \n",
    "                 w_subnet: nn.Module, ke_subnet: nn.Module, obstacles: bool = False):\n",
    "        super().__init__()\n",
    "        self.obstacles = obstacles\n",
    "        self.down_1 = nn.Sequential(nn.Conv2d(in_c + obstacles, 16, 3, padding=1, padding_mode='replicate'),\n",
    "                                    nn.InstanceNorm2d(16),\n",
    "                                    nn.LeakyReLU(),\n",
    "                                    nn.Conv2d(16, 32, 3, padding=1, padding_mode='replicate'),\n",
    "                                    nn.InstanceNorm2d(32),\n",
    "                                    nn.LeakyReLU())\n",
    "        self.down_2 = nn.Sequential(nn.Conv2d(32, 64, 3, padding=1, padding_mode='replicate'),\n",
    "                                    nn.AvgPool2d(2, 2),\n",
    "                                    nn.InstanceNorm2d(64),\n",
    "                                    nn.LeakyReLU())\n",
    "        \n",
    "        self.down_3 = nn.Sequential(nn.Conv2d(64, 128, 3, padding=1, padding_mode='replicate'),\n",
    "                                    nn.AvgPool2d(2, 2),\n",
    "                                    nn.InstanceNorm2d(128),\n",
    "                                    nn.LeakyReLU())\n",
    "        self.resblock_1 = ResBlock(128, 128)\n",
    "        self.resblock_2 = ResBlock(128, 128)\n",
    "        self.resblock_3 = ResBlock(128, 128)\n",
    "        self.resblock_4 = ResBlock(145, 145)\n",
    "        self.resblock_5 = ResBlock(145, 145)\n",
    "        self.resblock_6 = ResBlock(145, 145)\n",
    "        \n",
    "        self.subnet_conv = nn.Sequential(nn.Conv2d(128, 16, 3, padding=1, padding_mode='replicate'), \n",
    "                                         nn.LeakyReLU())\n",
    "        \n",
    "        self.up_1 = nn.Sequential(nn.Conv2d(177, 128, 3, padding=1, padding_mode='replicate'),\n",
    "                                  nn.InstanceNorm2d(128),\n",
    "                                  nn.LeakyReLU(),\n",
    "                                  nn.Conv2d(128, 128, 3, padding=1),\n",
    "                                  nn.InstanceNorm2d(128),\n",
    "                                  nn.LeakyReLU(),\n",
    "                                  nn.Upsample((128, 128), mode='bilinear', align_corners=True))\n",
    "        self.up_2 = nn.Sequential(nn.Conv2d(128, 64, 3, padding=1, padding_mode='replicate'),\n",
    "                                  nn.InstanceNorm2d(64),\n",
    "                                  nn.LeakyReLU(),\n",
    "                                  nn.Upsample((256, 256), mode='bilinear', align_corners=True))\n",
    "            \n",
    "        self.up_3 = nn.Sequential(nn.Conv2d(64, 32, 3, padding=1, padding_mode='replicate'),\n",
    "                                  nn.LeakyReLU())\n",
    "                        \n",
    "        self.conv_out = nn.Sequential(nn.Conv2d(32, out_c, 3, padding=1, padding_mode='replicate'), nn.ReLU())\n",
    "        \n",
    "        self.s_subnet = s_subnet\n",
    "        self.ke_subnet = ke_subnet\n",
    "        self.w_subnet = w_subnet\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, s: Optional[torch.Tensor] = None, \n",
    "                w: Optional[torch.Tensor] = None, ke: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor, \n",
    "                                                                                              torch.Tensor, torch.Tensor]:\n",
    "        x = self.down_1(x)\n",
    "        x = self.down_2(x)\n",
    "        x = self.down_3(x)\n",
    "        \n",
    "        x = self.resblock_1(x) \n",
    "        x = self.resblock_2(x)\n",
    "        x = self.resblock_3(x)\n",
    "        \n",
    "        y = self.subnet_conv(x)\n",
    "        \n",
    "        \n",
    "        y_s, s_out = self.s_subnet(y, s) # 16 x 8 x 8\n",
    "        y_ke, ke_out = self.ke_subnet(y, ke) # 1 x 16 x 16\n",
    "        \n",
    "        x = torch.cat([F.interpolate(y_s, size=(64, 64), mode='bilinear', align_corners=True), \n",
    "                       F.interpolate(y_ke, size=(64, 64), mode='bilinear', align_corners=True), x], dim=1)\n",
    "        \n",
    "        x = self.resblock_4(x)\n",
    "        x = self.resblock_5(x)\n",
    "        x = self.resblock_6(x)\n",
    "\n",
    "        y, w_out = self.w_subnet(x, w)\n",
    "        \n",
    "        \n",
    "        x = torch.cat([F.interpolate(y, size=(64, 64), mode='bilinear', align_corners=True), x], dim=1)\n",
    "        \n",
    "        x = self.up_1(x)\n",
    "        x = self.up_2(x)\n",
    "        x = self.up_3(x)\n",
    "        \n",
    "        x = self.conv_out(x)\n",
    "        \n",
    "        return x, s_out, w_out, ke_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "aeff0cf9",
   "metadata": {
    "cellId": "arshjhcamnpp3c9xdz4m2s"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from typing import Sequence\n",
    "def flatten(*tensors: Sequence[torch.Tensor], BATCH_SIZE: int) -> torch.Tensor:\n",
    "    return torch.cat([t.reshape(BATCH_SIZE, -1) for t in tensors], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "c15cbed9",
   "metadata": {
    "cellId": "dritc1dltthlp0ziaxxmts"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def curl(x):\n",
    "    dy = x[:, :, 1:] - x[:, :, :-1]\n",
    "    dx = -x[..., 1:] + x[..., :-1]\n",
    "    #dy = torch.cat([dy, dy[:, :, -1].unsqueeze(2)], dim=2)\n",
    "    #dx = torch.cat([dx, dx[..., -1].unsqueeze(3)], dim=3)\n",
    "    dy = F.pad(dy, (0, 0, 0, 1), mode='replicate')\n",
    "    dx = F.pad(dx, (0, 1, 0, 0), mode='replicate')\n",
    "    return torch.cat([dy,dx], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "id": "de3686c7",
   "metadata": {
    "cellId": "7x0yrx0wf7fnqw8xvoobg"
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Failed to run cell: internal error. Please try again",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#!g1.1\n",
    "def loss(f, pred, gt):\n",
    "    return sum(f(p, t) for p, t in zip(pred, gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "9efd1ddd",
   "metadata": {
    "cellId": "g9ms43whwusujesvauml2q"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "from typing import Mapping, Tuple\n",
    "\n",
    "def train_step(G: nn.Module, D: nn.Module, d: torch.Tensor, u: torch.Tensor, \n",
    "               s: Tuple[torch.Tensor], w: Tuple[torch.Tensor], ke: Tuple[torch.Tensor], \n",
    "               augm_inputs: Optional[Sequence[Tuple[torch.Tensor]]], \n",
    "               optG: Callable, optD: Callable, BATCH_SIZE: int, k: float, \n",
    "               l_adv: float = 0.2, l_l1: float = 1.0) -> Mapping[str, torch.Tensor]:\n",
    "    \n",
    "    optG.zero_grad(True)\n",
    "    \n",
    "    (s_, s), (w_, w), (ke_, ke) = s, w, ke\n",
    "    \n",
    "    g_out, g_s, g_w, g_ke = G(d, s_, w_, ke_)\n",
    "    g_u = curl(g_out)\n",
    "    \n",
    "    optD.zero_grad(True)\n",
    "    \n",
    "    gt_den = [d, s, w, ke]\n",
    "    \n",
    "    D_p_loss = loss(F.l1_loss, D(u), gt_den)\n",
    "    D_n_loss = loss(F.l1_loss, D(g_u.detach(), g_s.detach(), g_w.detach(), g_ke.detach()), gt_den)\n",
    "    \n",
    "    D_loss = D_p_loss - k * D_n_loss\n",
    "    D_loss.backward()\n",
    "    optD.step()\n",
    "    \n",
    "    #flatten_gd_out = flatten(*D(g_u, g_s, g_w, g_ke), BATCH_SIZE=BATCH_SIZE)\n",
    "    #flatten_vel = flatten(u, s_r, w_r, ke_r, BATCH_SIZE=BATCH_SIZE)\n",
    "    #dg_u, dg_s, dg_w, dg_ke = \n",
    "    \n",
    "    g_out_l1, s_l1, w_l1, ke_l1 = G(d)\n",
    "    g_u_l1 = curl(g_out_l1)\n",
    "    \n",
    "    #l1_out = flatten(curl(g_out_l1), s_l1, w_l1, ke_l1, BATCH_SIZE=BATCH_SIZE)\n",
    "    \n",
    "    #G_loss = l_adv * F.mse_loss(flatten_gd_out, flatten_den) + l_l1 * F.l1_loss(l1_out, flatten_vel)\n",
    "    G_adv_loss = l_adv * loss(F.l1_loss, D(g_u, g_s, g_w, g_ke), gt_den)\n",
    "    l1_loss = l_l1 * loss(F.l1_loss, [g_u_l1, s_l1, w_l1, ke_l1], [u, s, w, ke])\n",
    "    \n",
    "    if augm_inputs is not None:\n",
    "        u_augm, (w_augm_, w_augm), (ke_augm_, ke_augm) = augm_inputs\n",
    "        g_out_a, gs_augm, gw_augm, gke_augm = G(d, s, w_augm_, ke_augm_)\n",
    "        gu_augm = curl(g_out_a)\n",
    "        mod_loss = 0.6 * loss(F.l1_loss, D(gu_augm, gs_augm, gw_augm, gke_augm), [d, s, w_augm, ke_augm])\n",
    "        G_loss = G_adv_loss + l1_loss + mod_loss\n",
    "    else:\n",
    "        G_loss = G_adv_loss + l1_loss\n",
    "    \n",
    "    G_loss.backward()\n",
    "    optG.step()\n",
    "    \n",
    "    return {'G_loss': G_loss.detach().cpu().item(),\n",
    "            'D_p_loss': D_p_loss.detach().cpu().item(),\n",
    "            'D_n_loss': D_n_loss.detach().cpu().item()}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "573231d6",
   "metadata": {
    "cellId": "vc8hython7ojj79e825n2h"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Iterable\n",
    "\n",
    "def energy(vel: torch.Tensor) -> torch.Tensor:\n",
    "    return F.avg_pool2d(vel.pow(2).sum(1, keepdim=True), 16, 16)\n",
    "\n",
    "# def augment_energy(ke, den):\n",
    "#     std = ke.std((-2, -1), keepdim=True)\n",
    "#     return ke + F.avg_pool2d((torch.randn_like(den) / max(10, std.max())), 16, 16)\n",
    "\n",
    "def augment_velocity(vel):\n",
    "    std = vel.std()\n",
    "    vel = F.avg_pool2d(vel, 16, 16)\n",
    "    eps = torch.randn_like(vel) / 100\n",
    "    return torch.relu(F.interpolate(vel + eps, size=(256, 256), \n",
    "                                    mode='bilinear', align_corners=True))\n",
    "    \n",
    "def get_flags(x: torch.Tensor, p: float, size: Union[Sequence, int]) -> torch.Tensor:\n",
    "    mask = torch.tensor(np.random.binomial(1, 0.5, size=size), device=device)\n",
    "    return (1.0 - mask) * x - mask * torch.ones_like(x)\n",
    "    \n",
    "    \n",
    "def moving_avg(x, y, alpha: float):\n",
    "    return (1.0 - alpha) * x + alpha * y\n",
    "\n",
    "def train(G: nn.Module, D: nn.Module, optG: Callable, optD: Callable, train_loader: Iterable, \n",
    "          val_loader: Iterable, num_epochs: int, device: str, BATCH_SIZE: int, alpha: float = 0.3, beta: float = 0.3):\n",
    "    losses = {'G_loss': [],\n",
    "              'D_p_loss': [],\n",
    "              'D_n_loss': []}\n",
    "    k = gamma = 1e-4\n",
    "    D_p_loss = D_n_loss = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        for key in losses.keys():\n",
    "            losses[key].append([])\n",
    "        G.train(), D.train()\n",
    "        for den, vel, s in tqdm(train_loader):\n",
    "            den, vel, s = den.to(device), vel.to(device), s.to(device),\n",
    "            augm_inputs = None\n",
    "            if np.random.binomial(1, 0.25):\n",
    "                vel_augm = augment_velocity(vel)\n",
    "                ke_augm = energy(vel_augm)\n",
    "                vdx = F.pad((vel_augm[:, 1, :, 1:] - vel_augm[:, 1, :, :-1])[:, None], (0, 1, 0, 0), mode='replicate')\n",
    "                udy = F.pad((vel_augm[:, 0, 1:] - vel_augm[:, 0, :-1])[:, None], (0, 0, 0, 1), mode='replicate')\n",
    "                w_augm = vdx - udy\n",
    "                \n",
    "                ke_augm_ = get_flags(ke_augm, 0.5, (BATCH_SIZE, 1, 1, 1))\n",
    "                w_augm_ = get_flags(w_augm, 0.5, (BATCH_SIZE, 1, 1, 1))\n",
    "                \n",
    "                augm_inputs = [vel_augm, (w_augm_, w_augm), (ke_augm_, ke_augm)]\n",
    "                \n",
    "            ke = energy(vel)\n",
    "            vdx = F.pad((vel[:, 1, :, 1:] - vel[:, 1, :, :-1])[:, None], (0, 1, 0, 0), mode='replicate')\n",
    "            udy = F.pad((vel[:, 0, 1:] - vel[:, 0, :-1])[:, None], (0, 0, 0, 1), mode='replicate')\n",
    "            \n",
    "            w = vdx - udy\n",
    "            \n",
    "            ke_ = get_flags(ke, 0.5, (BATCH_SIZE, 1, 1, 1))\n",
    "            w_ = get_flags(w, 0.5, (BATCH_SIZE, 1, 1, 1))\n",
    "            s_ = get_flags(s, 0.5, (BATCH_SIZE, 1))\n",
    "            \n",
    "            loss = train_step(G, D, den, vel, (s_, s), (w_, w), (ke_, ke), augm_inputs, optG, optD, BATCH_SIZE, k)\n",
    "            \n",
    "            D_p_loss = moving_avg(D_p_loss, loss['D_p_loss'], alpha)\n",
    "            D_n_loss = moving_avg(D_n_loss, loss['D_n_loss'], alpha)\n",
    "            \n",
    "            gamma = D_p_loss / D_n_loss\n",
    "            k = moving_avg(k, gamma, beta)\n",
    "            \n",
    "            for key in loss.keys():\n",
    "                losses[key][-1].append(loss[key])\n",
    "        for key in losses.keys():\n",
    "            losses[key][-1] = np.mean(losses[key][-1])\n",
    "        \n",
    "        print(f'Epoch:{ epoch}')\n",
    "        \n",
    "        for key in losses.keys():\n",
    "            print(f'{key}: {losses[key][-1]}')\n",
    "        \n",
    "        G.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (den, vel, s) in tqdm(enumerate(val_loader)):\n",
    "                if np.random.binomial(1, p=0.005):\n",
    "                    den, vel, s = den.to(device), vel.to(device), s.to(device),\n",
    "                    g_out, s, w, ke = G(den)\n",
    "                    u = curl(g_out).cpu().numpy()\n",
    "                    plt.imshow(den[0][0].cpu().numpy(), cmap='gray')\n",
    "                    plt.title(f'den{i}_{epoch}')\n",
    "                    plt.savefig(f'den/den{i}_{epoch}.png')\n",
    "                    plt.clf()\n",
    "                    plt.imshow(vel.pow(2).sum(1)[0].cpu().numpy(), cmap='gray')\n",
    "                    plt.title(f'gt_vel{i}_{epoch}')\n",
    "                    plt.savefig(f'gt_vel/gt_vel{i}_{epoch}.png')\n",
    "                    plt.clf()\n",
    "                    plt.imshow(u[0][0], cmap='gray')\n",
    "                    plt.title(f'vel{i}_0_{epoch}')\n",
    "                    plt.savefig(f'vel/vel{i}_0_{epoch}.png')\n",
    "                    plt.clf()\n",
    "                    plt.imshow(u[0][1], cmap='gray')\n",
    "                    plt.title(f'vel{i}_1_{epoch}')\n",
    "                    plt.savefig(f'vel/vel{i}_1_{epoch}.png')\n",
    "                    plt.clf()\n",
    "                    plt.imshow(np.sqrt(u[0][1] ** 2 + u[0][0] ** 2), cmap='gray')\n",
    "                    plt.title(f'vel{i}_{epoch}')\n",
    "                    plt.savefig(f'vel/vel{i}_{epoch}.png')\n",
    "                    plt.clf()\n",
    "                    plt.imshow(w[0, 0].cpu().numpy(), cmap='gray')\n",
    "                    plt.title(f'w{i}_{epoch}')\n",
    "                    plt.savefig(f'vort/w{i}_{epoch}.png')\n",
    "                    plt.clf()\n",
    "        torch.save(G, 'G.pth'), torch.save(D, 'D.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "id": "9807195a",
   "metadata": {
    "cellId": "q5qydv81g7kf2ebn35dn3r"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "id": "002afa69",
   "metadata": {
    "cellId": "y590ywaalwis6tcwujc25j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G and D initialized\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "G_S_net = SubNetS(16)\n",
    "G_W_net = SubNetW(145)\n",
    "G_KE_net = SubNetKE(16)\n",
    "\n",
    "G = UNet(1, 1, G_S_net, G_W_net, G_KE_net)\n",
    "\n",
    "D_S_net = SubNetS(16)\n",
    "D_W_net = SubNetW(145)\n",
    "D_KE_net = SubNetKE(16)\n",
    "\n",
    "D = UNet(2, 1, D_S_net, D_W_net, D_KE_net)\n",
    "\n",
    "G.to(device), D.to(device)\n",
    "print('G and D initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "id": "307cab83",
   "metadata": {
    "cellId": "7gb4niwqo1d9icf0y2d8wh"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "optG = torch.optim.Adam(G.parameters(), lr=2e-5)\n",
    "optD = torch.optim.Adam(D.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb19ef7",
   "metadata": {
    "cellId": "pt89nisblgdcyuc7wfauh8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209db51196064f6697509ce3a483d223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=22800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:0\n",
      "G_loss: 120.30139159082582\n",
      "D_p_loss: 0.5937577515036652\n",
      "D_n_loss: 338.59026108754045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2774aaf52ea24c2d9cfbf8dd6c933a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe91b0751f5947bea10e1b65a3b40261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=22800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:1\n",
      "G_loss: 510.62269384806615\n",
      "D_p_loss: 0.4559019178531149\n",
      "D_n_loss: 1444.02645653595\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b5aa5548504127b4d0de2c5a7b5aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003ffaa057b041c9b26a48d90c25db79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=22800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:2\n",
      "G_loss: 1057.7391243730513\n",
      "D_p_loss: 0.37515485453403047\n",
      "D_n_loss: 3028.8530431058116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17b971ee05c4f24b1cd8fe68f38c530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff29d967baa9441ab2833a58f52aa992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=22800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "train(G, D, optG, optD, train_loader, val_loader, 10, device, BATCH_SIZE, alpha=0.1, beta=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aaf23b",
   "metadata": {
    "cellId": "iq5f5k81b2y4wol1l2p7m"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "with torch.no_grad():\n",
    "    den, vel, s = den.to(device), vel.to(device), s.to(device),\n",
    "    g_out, s, w, ke = G(den)\n",
    "    u = curl(g_out).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "id": "2760d303",
   "metadata": {
    "cellId": "5m8hizia73o7g8un7wwt8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "id": "d4ebb3aa",
   "metadata": {
    "cellId": "g8f0llbgeo8ajxkqhx4d4h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7a0c2c2e80>"
      ]
     },
     "execution_count": 925,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "vel = no_obs_val_dataset[797][1][None]\n",
    "vdx = F.pad((vel[:, 1, :, 1:] - vel[:, 1, :, :-1])[:, None], (0, 1, 0, 0), mode='replicate')\n",
    "udy = F.pad((vel[:, 0, 1:] - vel[:, 0, :-1])[:, None], (0, 0, 0, 1), mode='replicate')\n",
    "\n",
    "w = vdx - udy\n",
    "plt.imshow(w[0][0], cmap='gray')\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "id": "2d6ded5b",
   "metadata": {
    "cellId": "naignqea89a9an3zji8g9l"
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Failed to run cell: internal error. Please try again",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "    if i == 20:\n",
    "        break\n",
    "    plt.imshow(den[0, 0])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "7eafd645-2046-4633-b926-27282db9841c",
  "notebookPath": "den2vel.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
